{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c43684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81897bc1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Global warming ðŸŒŽ\n",
    "\n",
    "Consider the following three documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605cfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series([\n",
    "    'I really really want global peace',\n",
    "    'I must enjoy global warming',\n",
    "    'We must solve climate change'\n",
    "])\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b1a1e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent each document using the bag of words model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f0768",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(sentences.str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c734f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = {}\n",
    "for word in unique_words.index:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    counts_dict[word] = sentences.str.count(re_pat).astype(int).tolist()\n",
    "    \n",
    "counts_df = pd.DataFrame(counts_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf36677a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's now find the cosine similarity between each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c87ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b30ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_pair(s1, s2):\n",
    "    return np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f77468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the documentation of the .corr method to see how this works!\n",
    "counts_df.T.corr(sim_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ee569a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Issue:** Bag of words only encodes the **words** that each document uses, not their **meanings**.\n",
    "- \"I really really want global peace\" and \"We must solve climate change\" have similar meanings, but have no shared words, and thus a low cosine similarity.\n",
    "- \"I really really want global peace\" and \"I must enjoy global warming\" have very different meanings, but a relatively high cosine similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de88443",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pitfalls of the bag of words model\n",
    "\n",
    "Remember, the key assumption underlying the bag of words model is that **two documents are similar if they share many words in common**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacec5d1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model doesn't consider **order**.\n",
    "    - The job titles `'deputy fire chief'` and `'chief fire deputy'` are treated as the same."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f7a0e3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model doesn't consider the **meaning** of words.\n",
    "    - `'I love data science'` and `'I hate data science'` share 75% of their words, but have very different meanings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf0443e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The bag of words model treats all words as being equally important.\n",
    "    - `'deputy'` and `'fire'` have the same importance, even though `'fire'` is probably more important in describing someone's job title.\n",
    "    - <span style=\"color:red\"><b>Let's address this point.</b></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08543520",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc3cdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The importance of words\n",
    "\n",
    "**Issue:** The bag of words model doesn't know which words are \"important\" in a document. Consider the following document:\n",
    "\n",
    "<center>\"my brother has a friend named <b>sam</b> who has an uncle named <b>sam</b>\"</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec183579",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How do we determine which words are important?\n",
    "- The most common words (\"the\", \"has\") often **don't** have much meaning!\n",
    "- The very rare words are also less important!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ad374",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Goal:** Find a way of quantifying the importance of a word in a document by **balancing the above two factors**, i.e. find the word that **best summarizes** a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe4d0ca0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency\n",
    "\n",
    "- The **term frequency** of a word (term) $t$ in a document $d$, denoted $\\text{tf}(t, d)$ is the proportion of words in document $d$ that are equal to $t$.\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6edd0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: Words that occur often within a document are important to the document's meaning.\n",
    "    - If $\\text{tf}(t, d)$ is large, then word $t$ occurs often in $d$.\n",
    "    - If $\\text{tf}(t, d)$ is small, then word $t$ does not occur often $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0cb0c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inverse document frequency\n",
    "\n",
    "- The **inverse document frequency** of a word $t$ in a set of documents $d_1, d_2, ...$ is\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25153c15",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition: If a word appears in every document (like \"the\" or \"has\"), it is probably not a good summary of any one document.\n",
    "    - If $\\text{idf}(t)$ is large, then $t$ is rarely found in documents.\n",
    "    - If $\\text{idf}(t)$ is small, then $t$ is commonly found in documents.\n",
    "    - Think of $\\text{idf}(t)$ as the \"rarity factor\" of $t$ across documents â€“ the larger $\\text{idf}(t)$ is, the more rare $t$ is."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5ce4c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intuition\n",
    "\n",
    "$$\\text{tf}(t, d) = \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}}$$\n",
    "\n",
    "$$\\text{idf}(t) = \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right)$$\n",
    "\n",
    "**Goal:** Quantify how well word $t$ **summarizes** document $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3c7776",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency-inverse document frequency\n",
    "\n",
    "The **term frequency-inverse document frequency (TF-IDF)** of word $t$ in document $d$ is the product:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\\text{tfidf}(t, d) &= \\text{tf}(t, d) \\cdot \\text{idf}(t) \\\\\\ &= \\frac{\\text{# of occurrences of $t$ in $d$}}{\\text{total # of words in $d$}} \\cdot \\log \\left(\\frac{\\text{total # of documents}}{\\text{# of documents in which $t$ appears}} \\right) \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11bd2c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\text{tfidf}(t, d)$ is large, then $t$ is a good summary of $d$, because $t$ occurs often in $d$ but rarely across all documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc456876",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- TF-IDF is a **heuristic** â€“ it has no probabilistic justification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a222c1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- To know if $\\text{tfidf}(t, d)$ is large for one particular word $t$, we need to compare it to $\\text{tfidf}(t_i, d)$, for several different words $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef231326",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Computing TF-IDF\n",
    "\n",
    "**Question:** What is the TF-IDF of \"global\" in the second sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8388d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e7306",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f0604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = sentences.iloc[1].count('global') / len(sentences.iloc[1].split())\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45953f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idf = np.log(len(sentences) / sentences.str.contains('global').sum())\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0989da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf * idf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3e1607",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question:** Is this big or small? Is \"global\" the **best** summary of the second sentence?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af81a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### TF-IDF of all words in all documents\n",
    "\n",
    "On its own, the TF-IDF of a word in a document doesn't really tell us anything; we must compare it to TF-IDFs of other words in that same document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212905a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405eab7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = np.unique(sentences.str.split().sum())\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_dict = {}\n",
    "\n",
    "for word in unique_words:\n",
    "    re_pat = fr'\\b{word}\\b'\n",
    "    tf = sentences.str.count(re_pat) / sentences.str.split().str.len()\n",
    "    idf = np.log(len(sentences) / sentences.str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] = tf * idf\n",
    "    \n",
    "tfidf = pd.DataFrame(tfidf_dict).set_index(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00f89d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39de10",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Interpreting TF-IDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7e5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734cadb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The above DataFrame tells us that:\n",
    "- the TF-IDF of `'peace'` in the first sentence is 0.183102,\n",
    "- the TF-IDF of `'climate'` in the second sentence is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cafb1ed",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that there are two ways that $\\text{tfidf}(t, d) = \\text{tf}(t, d) \\cdot \\text{idf}(t)$ can be 0:\n",
    "- If $t$ appears in every document, because then $\\text{idf}(t) = \\log (\\frac{\\text{# documents}}{\\text{# documents}}) = \\log(1) = 0$.\n",
    "- If $t$ does not appear in document $d$, because then $\\text{tf}(t, d) = \\frac{0}{\\text{len}(d)} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af48d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The word that **best summarizes** a document is the word with the highest TF-IDF for that document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804d8e94",
   "metadata": {},
   "source": [
    "Look closely at the rows of `tfidf` â€“ in documents 1 and 2, the max TF-IDF is not unique!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b92963d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: State of the Union addresses ðŸŽ¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980d913",
   "metadata": {},
   "source": [
    "### State of the Union addresses\n",
    "\n",
    "The 2023 State of the Union address was on February 7th, 2023.\n",
    "It is an annual message delivered by the president of the United States to a joint session of the United States Congress near the beginning of most calendar years on the current condition of the nation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec32713",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db49b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sotu = open('stateoftheunion1790-2023.txt').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05569714",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sotu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66057eca",
   "metadata": {},
   "source": [
    "The entire **corpus** (another word for \"set of documents\") is over 10 million characters long... let's not display it in our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a987af22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(sotu[:16000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a60c4f",
   "metadata": {},
   "source": [
    "Each speech is separated by `'***'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d60dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = sotu.split('\\n***\\n')[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca0971",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(speeches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723eec4",
   "metadata": {},
   "source": [
    "Note that each \"speech\" currently contains other information, like the name of the president and the date of the address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818f52e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(speeches[-1][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea89846",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's extract just the speech text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa932c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_struct(speech):\n",
    "    L = speech.strip().split('\\n', maxsplit=3)\n",
    "    L[3] = re.sub(r\"[^A-Za-z' ]\", ' ', L[3]).lower()\n",
    "    return dict(zip(['speech', 'president', 'date', 'contents'], L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5438e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df = pd.DataFrame(list(map(extract_struct, speeches)))\n",
    "speeches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df1fade",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding the most important words in each speech\n",
    "\n",
    "Here, a \"document\" is a speech. We have 233 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5a1d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926bcc2d",
   "metadata": {},
   "source": [
    "A rough sketch of what we'll compute:\n",
    "\n",
    "```\n",
    "for each word t:\n",
    "    for each speech d:\n",
    "        compute tfidf(t, d)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d40a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = pd.Series(speeches_df['contents'].str.split().sum()).value_counts()\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = unique_words.iloc[:500].index\n",
    "\n",
    "tfidf_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf = np.log(len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum())\n",
    "    tfidf_dict[word] =  tf * idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a8867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = pd.DataFrame(tfidf_dict)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f34b9e",
   "metadata": {},
   "source": [
    "Note that the TF-IDFs of many common words are all 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c15f5bf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summarizing speeches\n",
    "\n",
    "By using `idxmax`, we can find the word with the highest TF-IDF in each speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b7f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = tfidf.idxmax(axis=1)\n",
    "summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aad3811",
   "metadata": {},
   "source": [
    "What if we want to see the 5 words with the highest TF-IDFs, for each speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbdd477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_largest(row):\n",
    "    return list(row.index[row.argsort()][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af340d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = tfidf.apply(five_largest, axis=1)\n",
    "keywords_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762dd5e",
   "metadata": {},
   "source": [
    "Run the cell below to see every single row of `keywords_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf737b3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', 300):\n",
    "    display(keywords_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847a013b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Aside: What if we remove the $\\log$ from $\\text{idf}(t)$?\n",
    "\n",
    "Let's try it and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfb892",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl_dict = {}\n",
    "tf_denom = speeches_df['contents'].str.split().str.len()\n",
    "for word in unique_words:\n",
    "    re_pat = fr' {word} ' # Imperfect pattern for speed.\n",
    "    tf = speeches_df['contents'].str.count(re_pat) / tf_denom\n",
    "    idf_nl = len(speeches_df) / speeches_df['contents'].str.contains(re_pat).sum()\n",
    "    tfidf_nl_dict[word] =  tf * idf_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdd2a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_nl = pd.DataFrame(tfidf_nl_dict)\n",
    "tfidf_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54838d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords_nl = tfidf_nl.apply(five_largest, axis=1)\n",
    "keywords_nl_df = pd.concat([\n",
    "    speeches_df['president'],\n",
    "    speeches_df['date'],\n",
    "    keywords_nl\n",
    "], axis=1)\n",
    "keywords_nl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8186413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
