{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "orange-richardson",
   "metadata": {},
   "source": [
    "# Lab 4 â€“ APIs and Web Scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hawaiian-visibility",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "In this homework, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `hw.py` file that is imported into the current notebook.\n",
    "\n",
    "**Do not change the function names in the `hw.py` file!**\n",
    "- The functions in the `hw.py` file are how your assignment is graded, and they are graded by their name.\n",
    "\n",
    "\n",
    "**Tips for working in the notebook**:\n",
    "- The notebooks serve to present the questions and give you a place to present your results for later review.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `hw.py` file. You can write code here, but make sure that all of your real work is in the `hw.py` file.\n",
    "\n",
    "**Tips for developing in the `hw.py` file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional helper functions to solve the homework! \n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-assembly",
   "metadata": {},
   "source": [
    "### Importing code from `hw.py`\n",
    "\n",
    "* We import our `hw.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `hw.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `hw.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `hw.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `hw` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "increasing-kernel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "covered-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "engaged-depression",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import time\n",
    "import requests\n",
    "import bs4\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-sentence",
   "metadata": {},
   "source": [
    "## Question 1 â€“ Practice with HTML Tags ðŸ“Ž\n",
    "\n",
    "In this question, you won't write any Python code! Instead, you'll create a very basic `.html` file, named `hw04_1.html`, that satisfies the following conditions:\n",
    "\n",
    "- It must have `<title>` and `<head>` tags.\n",
    "- It must also have `<body>` tags. Within the `<body>` tags, it must have:\n",
    "    - At least two headers.\n",
    "    * At least three images.\n",
    "        - At least one image must be a local file.\n",
    "        - At least one image must be linked to online source.\n",
    "        - At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages.\n",
    "    * At least one table with two rows and two columns.\n",
    "    \n",
    "\n",
    "Make sure to save your file as `hw04_1.html`, and save it in the same directory as `hw.py`. \n",
    "   \n",
    "\n",
    "***Notes:*** \n",
    "- You can write and view basic HTML with a Jupyter Notebook, using either a Markdown cell or by using the `IPython.display.HTML` function (which takes in a string of HTML and renders it).\n",
    "- If you write your HTML code within a Jupyter Notebook, you should later copy your code into a text editor and save it with the `.html` extension. You could also write your HTML in a text editor directly.\n",
    "- Be sure to open your final `.html` file in a browser and make sure it looks correct on its own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-procedure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-queensland",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documentary-flower",
   "metadata": {},
   "source": [
    "## Question 2 â€“ Scraping an Online Bookstore ðŸ“š\n",
    "\n",
    "Browse through the following fake online bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Your job is to scrape the website, collecting data on all books that have:\n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and \n",
    "- **belong to specific categories** (more details below). \n",
    "\n",
    "You will extract the information into a DataFrame that looks like the one below.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>UPC</th>\n",
    "      <th>Product Type</th>\n",
    "      <th>Price (excl. tax)</th>\n",
    "      <th>Price (incl. tax)</th>\n",
    "      <th>Tax</th>\n",
    "      <th>Availability</th>\n",
    "      <th>Number of reviews</th>\n",
    "      <th>Category</th>\n",
    "      <th>Rating</th>\n",
    "      <th>Description</th>\n",
    "      <th>Title</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>0</th>\n",
    "      <td>e10e1e165dc8be4a</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£22.60</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Default</td>\n",
    "      <td>Four</td>\n",
    "      <td>For readers of Laura Hillenbrand's Seabiscuit...</td>\n",
    "      <td>The Boys in the Boat: Nine Americans...</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>1</th>\n",
    "      <td>c2e46a2ee3b4a322</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£25.27</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>A Michelin two-star chef at twenty-eight, Violette...</td>\n",
    "      <td>Chase Me (Paris Nights #2)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>2</th>\n",
    "      <td>00bfed9e18bb36f3</td>\n",
    "      <td>Books</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£34.53</td>\n",
    "      <td>Ã‚Â£0.00</td>\n",
    "      <td>In stock (19 available)</td>\n",
    "      <td>0</td>\n",
    "      <td>Romance</td>\n",
    "      <td>Five</td>\n",
    "      <td>No matter how busy he keeps himself...</td>\n",
    "      <td>Black Dust</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "To do so, implement the following functions.\n",
    "\n",
    "#### `extract_book_links`\n",
    "\n",
    "Create a function `extract_book_links` that takes in the content of a page that contains book listings as a **string of HTML**, and returns a **list** of URLs of book-specific pages for all books with **_at least_ a four-star rating and a price _strictly_ less than Â£50**. \n",
    "\n",
    "<br>\n",
    "\n",
    "#### `get_product_info`\n",
    "\n",
    "Create a function `get_product_info` that takes in the content of a book-specific page as a **string of HTML**, and a list `categories` of book categories. If the input book is in the list of `categories`, `get_product_info` should return a dictionary corresponding to a row in the DataFrame in the image above (where the keys are the column names and the values are the row values). If the input book is not in the list of `categories`, return `None`.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `scrape_books`\n",
    "\n",
    "Finally, put everything together. Create a function `scrape_books` that takes in an integer `k` and a list `categories` of book categories. `scrape_books` should use `requests` to scrape the first `k` pages of the bookstore and return a DataFrame of only the books that have \n",
    "- **_at least_ a four-star rating**, and\n",
    "- **a price _strictly_ less than Â£50**, and\n",
    "- **a category that is in the list `categories`**.\n",
    "\n",
    "<br>\n",
    "\n",
    "***Notes:***\n",
    "- The first page of the bookstore is at http://books.toscrape.com. Subsequent pages can be found by clicking the \"Next\" button at the bottom of the page.\n",
    "- When instantiating `bs4.BeautifulSoup` objects, use the optional argument `features='lxml'` to suppress any warnings.\n",
    "- Only `scrape_books` needs to make a `GET` request.\n",
    "- Don't worry about typecasting, i.e. it's fine if `'Number of reviews'` is not stored as type `int`. Also, don't worry if you run into encoding errors in your price columns (as the example DataFrame at the top of this cell contains)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "entitled-container",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(f'http://books.toscrape.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e0e3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SJTU\\II-Summer\\STAT471\\Lab\\lab4\\exercise\\hw.py:43: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 43 of the file c:\\SJTU\\II-Summer\\STAT471\\Lab\\lab4\\exercise\\hw.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = bs4.BeautifulSoup(text)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['seven-brief-lessons-on-physics_219/index.html',\n",
       " 'scarlet-the-lunar-chronicles-2_218/index.html',\n",
       " 'saga-volume-3-saga-collected-editions-3_216/index.html',\n",
       " 'running-with-scissors_215/index.html',\n",
       " 'rise-of-the-rocket-girls-the-women-who-propelled-us-from-missiles-to-the-moon-to-mars_213/index.html',\n",
       " 'ready-player-one_209/index.html']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbdb2901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"../../index.html\">Home</a>,\n",
       " <a href=\"../category/books_1/index.html\">Books</a>,\n",
       " <a href=\"../category/books/default_15/index.html\">Default</a>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = ['Default']\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "text = open(get_product_info_fp, encoding='utf-8').read()\n",
    "soup = bs4.BeautifulSoup(text)\n",
    "breadcrumb = soup.find('ul', class_='breadcrumb')\n",
    "category = breadcrumb.find_all('a')\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "failing-grace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\SJTU\\II-Summer\\STAT471\\Lab\\lab4\\exercise\\hw.py:73: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 73 of the file c:\\SJTU\\II-Summer\\STAT471\\Lab\\lab4\\exercise\\hw.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = bs4.BeautifulSoup(text)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Title': 'Frankenstein', 'Category': 'Default', 'Rating': 'Two', 'Description': \"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\", 'UPC': 'a492f49a3e2b6a71', 'Product Type': 'Books', 'Price (excl. tax)': 'Â£38.00', 'Price (incl. tax)': 'Â£38.00', 'Tax': 'Â£0.00', 'Availability': 'In stock (1 available)', 'Number of reviews': '0'}\n",
      "           Title Category Rating  \\\n",
      "0  Sharp Objects  Mystery   Four   \n",
      "\n",
      "                                         Description               UPC  \\\n",
      "0  WICKED above her hipbone, GIRL across her hear...  e00eb4fd7b871a48   \n",
      "\n",
      "  Product Type Price (excl. tax) Price (incl. tax)     Tax  \\\n",
      "0        Books           Ã‚Â£47.82           Ã‚Â£47.82  Ã‚Â£0.00   \n",
      "\n",
      "              Availability Number of reviews  \n",
      "0  In stock (20 available)                 0  \n"
     ]
    }
   ],
   "source": [
    "# don't delete this cell, but do run it \n",
    "\n",
    "# doctest for extract_book_links \n",
    "extract_book_links_fp = os.path.join('data', 'products.html')\n",
    "extract_book_out = extract_book_links(\n",
    "    open(extract_book_links_fp, encoding='utf-8').read()\n",
    ")\n",
    "extract_book_url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "\n",
    "# doc tests for get product info\n",
    "get_product_info_fp = os.path.join('data', 'Frankenstein.html')\n",
    "get_product_info_out = get_product_info(\n",
    "    open(get_product_info_fp, encoding='utf-8').read(), ['Default']\n",
    ")\n",
    "\n",
    "# doc test for scrape books \n",
    "scrape_books_out = scrape_books(1, ['Mystery'])\n",
    "\n",
    "print(get_product_info_out)\n",
    "\n",
    "print(scrape_books_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-immunology",
   "metadata": {},
   "source": [
    "## Question 3 â€“ API Requests ðŸ¤‘\n",
    "\n",
    "Let's calculate statistics of your favorite stocks by pulling data from a public API. The API we will work with can be found at https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price. Specifically, we will use the \"**Stock Historical Price**\" endpoint (search for it at the linked page).\n",
    "\n",
    "Some relevant definitions:\n",
    "- Ticker: A short code that refers to a stock. For example, Apple's ticker is AAPL and Ford's ticker is F. \n",
    "- Open: The price of a stock at the beginning of a trading day.\n",
    "- Close: The price of a stock at the end of a trading day.\n",
    "- Volume: The total number of shares traded in a day.\n",
    "- Percent change: The difference in price with respect to the original price, as a percentage.\n",
    "\n",
    "To make requests to the aforementioned API, you will need an API key. In order to get one, you will need to make an account at the website. Once you've signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. You will have to encode your API key in the URL that you make requests to; see a complete example of such a request at the right side of the [documentation](https://site.financialmodelingprep.com/developer/docs#Stock-Historical-Price).\n",
    "\n",
    "Implement the following two functions.\n",
    "\n",
    "#### `stock_history`\n",
    "\n",
    "Create a function `stock_history` which takes in a string `ticker` and two integers, `year` and `month`, and returns a DataFrame containing the price history for that stock in that month. Keep all of the attributes that are returned by the API.\n",
    "\n",
    "***Notes:***\n",
    "- Read the API documentation if you get stuck!\n",
    "- [`pd.date_range`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html) takes in two dates and returns a sequence of all dates between the two dates, excluding the right endpoint. How might this be helpful?\n",
    "- The [`requests.get`](https://docs.python-requests.org/en/master/user/quickstart/) function returns a Response object, not the data itself. Use the `json` method on the Response object to extract the relevant JSON, as we did in Lecture 15 (you don't need to `import json` to do this).\n",
    "- You can instantiate a DataFrame using a sequence of dictionaries.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `stock_stats`\n",
    "\n",
    "Create a function `stock_stats` that takes in a DataFrame outputted by `stock_history` and returns a **tuple** of two numbers:\n",
    "1. The percent change of the stock throughout the month as a **percentage**.\n",
    "2. An estimate of the total transaction volume **in billion of dollars** for that month.\n",
    "\n",
    "Both values in the tuple should be **strings** that contain numbers rounded to two decimal places. Add a plus or minus sign in front of the percent change, and make sure that the total transaction volume string ends in a `'B'`.\n",
    "\n",
    "**To compute the percent change**, use the opening price on the first day of the month as the starting price and the closing price on the last day of the month as the ending price.\n",
    "\n",
    "**To compute the total transaction volume**, assume that on any given day, the average price of a share is the midpoint of the high and low price for that day.\n",
    "\n",
    "$$ \\text{Estimated Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Average Price} $$\n",
    "\n",
    "For example, suppose there are only three days in March- March 1st, March 2nd, and March 3rd.\n",
    "\n",
    "If BYND (Beyond Meat) opens at \\\\$4 on March 1st and closes at \\\\$5 on March 3rd, its percent change for the month of March is $$\\frac{\\$5-\\$4}{\\$4} = +25.00\\%$$\n",
    "\n",
    "Suppose the high and low prices and volumes of BYND on each day are given below.\n",
    "- March 1st: high \\\\$5, low \\\\$3, volume 500 million (0.5 billion)\n",
    "- March 2nd: high \\\\$5.5, low \\\\$2.5, volume 1 billion\n",
    "- March 3rd: high \\\\$5.25, low \\\\$4, volume 500 million (0.5 billion)\n",
    "\n",
    "Then, the estimated total transaction volume is\n",
    "$$\\frac{\\$5 + \\$3}{2} \\cdot 0.5 B + \\frac{\\$5.5 + \\$2.5}{2} \\cdot 1 B + \\frac{\\$5.25 + \\$4}{2} \\cdot 0.5 B = 8.3125B$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "serious-birthday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-01 2019-06-30\n"
     ]
    }
   ],
   "source": [
    "history = stock_history('BYND', 2019, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "healthy-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'+54.29%'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "close_price = history['close'].iloc[0]\n",
    "open_price = history['open'].iloc[-1]\n",
    "percent_change = (close_price - open_price) / open_price * 100\n",
    "percent_change_str = f'{percent_change:.2f}%'\n",
    "if percent_change > 0 :\n",
    "    percent_change_str = '+' + percent_change_str\n",
    "percent_change_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df233c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33.64B'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_price = 0.5 * (history['high']+ history['low'])\n",
    "total_volume = sum(history['volume'] * average_price) / 1e9\n",
    "total_volume_str = f'{total_volume:.2f}B'\n",
    "total_volume_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "vital-forge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date    open    high       low   close    adjClose    volume  \\\n",
      "0   2019-06-28  165.30  168.80  159.5500  160.68  160.679993   7315297   \n",
      "1   2019-06-27  157.31  164.79  155.4500  162.91  162.910004   5719421   \n",
      "2   2019-06-26  160.10  162.25  153.0200  160.48  160.479996   6378629   \n",
      "3   2019-06-25  138.50  150.69  138.3425  150.60  150.600006   6682929   \n",
      "4   2019-06-24  151.88  152.70  138.0000  140.99  140.990005   6538497   \n",
      "5   2019-06-21  153.54  161.79  150.0000  154.13  154.130005   7474586   \n",
      "6   2019-06-20  173.00  174.00  163.3000  165.17  165.169998   6660492   \n",
      "7   2019-06-19  171.37  174.45  162.2500  169.28  169.279999   9451961   \n",
      "8   2019-06-18  200.00  201.88  160.7000  169.89  169.889999  23966910   \n",
      "9   2019-06-17  163.18  171.19  160.6111  169.96  169.960007  14626683   \n",
      "10  2019-06-14  142.01  157.90  141.8000  151.48  151.479996  14964553   \n",
      "11  2019-06-13  141.52  146.45  134.2500  141.39  141.389999   9474562   \n",
      "12  2019-06-12  133.99  150.45  131.5632  141.97  141.970001  16900631   \n",
      "13  2019-06-11  145.25  150.00  125.2300  126.04  126.040001  15515979   \n",
      "14  2019-06-10  155.70  186.43  147.0000  168.10  168.100006  24978735   \n",
      "15  2019-06-07  130.00  149.46  120.7600  138.65  138.649994  23916747   \n",
      "16  2019-06-06  102.00  102.25   98.8500   99.50   99.500000   6483991   \n",
      "17  2019-06-05  105.50  105.50   99.6400  102.60  102.599998   4283474   \n",
      "18  2019-06-04  101.25  103.50   97.8200  103.41  103.410004   5484873   \n",
      "19  2019-06-03  104.14  108.67   95.6620   96.16   96.160004   8027710   \n",
      "\n",
      "    unadjustedVolume  change  changePercent    vwap        label  \\\n",
      "0            7315300   -4.62       -2.79000  163.92  June 28, 19   \n",
      "1            5731400    5.60        3.56000  160.43  June 27, 19   \n",
      "2            6378600    0.38        0.23735  157.99  June 26, 19   \n",
      "3            6632500   12.10        8.74000  146.35  June 25, 19   \n",
      "4            6538500  -10.89       -7.17000  142.69  June 24, 19   \n",
      "5            7474600    0.59        0.38426  155.01  June 21, 19   \n",
      "6            6660500   -7.83       -4.53000  167.58  June 20, 19   \n",
      "7            9452000   -2.09       -1.22000  167.61  June 19, 19   \n",
      "8           23966900  -30.11      -15.06000  175.95  June 18, 19   \n",
      "9           14626700    6.78        4.15000  166.83  June 17, 19   \n",
      "10          14964600    9.47        6.67000  151.75  June 14, 19   \n",
      "11           9474600   -0.13       -0.09186  141.31  June 13, 19   \n",
      "12          16918600    7.98        5.96000  140.38  June 12, 19   \n",
      "13          15516000  -19.21      -13.23000  136.34  June 11, 19   \n",
      "14          24986000   12.40        7.96000  167.94  June 10, 19   \n",
      "15          23916700    8.65        6.65000  132.62  June 07, 19   \n",
      "16           6484000   -2.50       -2.45000  105.64  June 06, 19   \n",
      "17           4283500   -2.90       -2.75000  102.18  June 05, 19   \n",
      "18           5484900    2.16        2.13000  100.64  June 04, 19   \n",
      "19           8027700   -7.98       -7.66000  103.12  June 03, 19   \n",
      "\n",
      "    changeOverTime  \n",
      "0        -0.027900  \n",
      "1         0.035600  \n",
      "2         0.002374  \n",
      "3         0.087400  \n",
      "4        -0.071700  \n",
      "5         0.003843  \n",
      "6        -0.045300  \n",
      "7        -0.012200  \n",
      "8        -0.150600  \n",
      "9         0.041500  \n",
      "10        0.066700  \n",
      "11       -0.000919  \n",
      "12        0.059600  \n",
      "13       -0.132300  \n",
      "14        0.079600  \n",
      "15        0.066500  \n",
      "16       -0.024500  \n",
      "17       -0.027500  \n",
      "18        0.021300  \n",
      "19       -0.076600  \n",
      "7 6\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# don't delete this cell, but do run it \n",
    "\n",
    "# doctest for stock_history\n",
    "history = stock_history('BYND', 2019, 6)\n",
    "print(history)\n",
    "# doctest for stock_stats\n",
    "stats = stock_stats(history)\n",
    "\n",
    "\n",
    "print(len(stats[0]), len(stats[1]))\n",
    "\n",
    "print(float(stats[0][1:-1]) > 30)\n",
    "\n",
    "print(float(stats[1][:-1]) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-channels",
   "metadata": {},
   "source": [
    "## Congratulations! You're done! \n",
    "\n",
    "Submit the following three files to Canvas:\n",
    "- `hw.py`\n",
    "- `hw04_1.html`\n",
    "- `hw04.ipynb`\n",
    "- The local image you embedded in `hw04_1.html`\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> os.path.exists('lab06_1.html')\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> extract_book_out[1] == extract_book_url\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> isinstance(get_product_info_out, dict)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> 'Category' in get_product_info_out.keys()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> get_product_info_out['Rating'] == 'Two'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out.shape == (1, 11)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Rating'][0] == 'Four'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> scrape_books_out['Title'][0] == 'Sharp Objects'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> history.shape == (20, 13)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> history.label.iloc[-1] == 'June 03, 19'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (len(stats[0]), len(stats[1])) == (7, 6)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> (float(stats[0][1:-1]) > 30) == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> float(stats[1][:-1]) > 1 == True\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> stats[1][-1] == 'B'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> comments_doctest.shape == (18, 5)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments_doctest.loc[5, 'by'] == 'RobAtticus'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        },
        {
         "code": ">>> comments_doctest.loc[5, 'time'].day == 31\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "fa21447ba3ca0ac29cfe033d1e623e3db9da50a3031a1ad33c9e1c367d9ba6e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
