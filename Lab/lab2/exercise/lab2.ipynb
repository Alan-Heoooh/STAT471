{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro-hw2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Homework 2: Food Safety (50 Pts)\n",
    "## Cleaning and Exploring Data with Pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## This Assignment\n",
    "\n",
    "In this homework, we will investigate restaurant food safety scores for restaurants in San Francisco. The scores and violation information have been [made available by the San Francisco Department of Public Health](https://data.sfgov.org/Health-and-Social-Services/Restaurant-Scores-LIVES-Standard/pyih-qa8i). The main goal for this assignment is to walk through the process of Data Cleaning and EDA. \n",
    "\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Reading simple csv files and using Pandas\n",
    "* Working with data at different levels of granularity\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Exploring characteristics and distributions of individual variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import os # Used to interact with the file system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Verifying Data\n",
    "\n",
    "There are several tables in the data folder. Let's attempt to load `bus.csv`, `ins2vio.csv`, `ins.csv`, and `vio.csv` into pandas dataframes with the following names: `bus`, `ins2vio`, `ins`, and `vio` respectively.\n",
    "\n",
    "*Note:* Because of character encoding issues one of the files (`bus`) will require an additional argument `encoding='ISO-8859-1'` when calling `pd.read_csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to directory containing data\n",
    "dsDir = Path('data')\n",
    "\n",
    "bus = pd.read_csv(dsDir/'bus.csv', encoding='ISO-8859-1')\n",
    "ins2vio = pd.read_csv(dsDir/'ins2vio.csv')\n",
    "ins = pd.read_csv(dsDir/'ins.csv')\n",
    "vio = pd.read_csv(dsDir/'vio.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you've read in the files, let's try some `pd.DataFrame` methods ([docs](https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html)).\n",
    "Use the `DataFrame.head` method to show the top few lines of the `bus`, `ins`, and `vio` dataframes. To show multiple return outputs in one single cell, you can useÂ `display()`. Currently, running the cell below will display the first few lines of the `bus` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `DataFrame.describe` method can also be handy for computing summaries of numeric columns of our dataframes. Try it out with each of our 4 dataframes. Below, we have used the method to give a summary of the `bus` dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform some sanity checks for you to verify that the data was loaded with the correct structure. Run the following cells to load some basic utilities (you do not need to change these at all):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we check the basic structure of the data frames you created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(bus.columns == ['business id column', 'name', 'address', 'city', 'state', 'postal_code',\n",
    "                           'latitude', 'longitude', 'phone_number'])\n",
    "assert 6250 <= len(bus) <= 6260\n",
    "\n",
    "assert all(ins.columns == ['iid', 'date', 'score', 'type'])\n",
    "assert 26660 <= len(ins) <= 26670\n",
    "\n",
    "assert all(vio.columns == ['description', 'risk_category', 'vid'])\n",
    "assert 60 <= len(vio) <= 65\n",
    "\n",
    "assert all(ins2vio.columns == ['iid', 'vid'])\n",
    "assert 40210 <= len(ins2vio) <= 40220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll check that the statistics match what we expect. The following are hard-coded statistical summaries of the correct data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_summary = pd.DataFrame(**{'columns': ['business id column', 'latitude', 'longitude'],\n",
    " 'data': {'business id column': {'50%': 75685.0, 'max': 102705.0, 'min': 19.0},\n",
    "  'latitude': {'50%': -9999.0, 'max': 37.824494, 'min': -9999.0},\n",
    "  'longitude': {'50%': -9999.0,\n",
    "   'max': 0.0,\n",
    "   'min': -9999.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "ins_summary = pd.DataFrame(**{'columns': ['score'],\n",
    " 'data': {'score': {'50%': 76.0, 'max': 100.0, 'min': -1.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "vio_summary = pd.DataFrame(**{'columns': ['vid'],\n",
    " 'data': {'vid': {'50%': 103135.0, 'max': 103177.0, 'min': 103102.0}},\n",
    " 'index': ['min', '50%', 'max']})\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "print('What we expect from your Businesses dataframe:')\n",
    "display(bus_summary)\n",
    "print('What we expect from your Inspections dataframe:')\n",
    "display(ins_summary)\n",
    "print('What we expect from your Violations dataframe:')\n",
    "display(vio_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below defines a testing function that we'll use to verify that your data has the same statistics as what we expect. Run these cells to define the function. The `df_allclose` function has this name because we are verifying that all of the statistics for your dataframe are close to the expected values. Why not `df_allequal`? It's a bad idea in almost all cases to compare two floating point values like 37.780435, as rounding error can cause spurious failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Run this cell to load this utility comparison function that we will use in various\n",
    "tests below \n",
    "\n",
    "Do not modify the function in any way.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def df_allclose(actual, desired, columns=None, rtol=5e-2):\n",
    "    \"\"\"Compare selected columns of two dataframes on a few summary statistics.\n",
    "    \n",
    "    Compute the min, median and max of the two dataframes on the given columns, and compare\n",
    "    that they match numerically to the given relative tolerance.\n",
    "    \n",
    "    If they don't match, an AssertionError is raised (by `numpy.testing`).\n",
    "    \"\"\"    \n",
    "    # summary statistics to compare on\n",
    "    stats = ['min', '50%', 'max']\n",
    "    \n",
    "    # For the desired values, we can provide a full DF with the same structure as\n",
    "    # the actual data, or pre-computed summary statistics.\n",
    "    # We assume a pre-computed summary was provided if columns is None. In that case, \n",
    "    # `desired` *must* have the same structure as the actual's summary\n",
    "    if columns is None:\n",
    "        des = desired\n",
    "        columns = desired.columns\n",
    "    else:\n",
    "        des = desired[columns].describe().loc[stats]\n",
    "\n",
    "    # Extract summary stats from actual DF\n",
    "    act = actual[columns].describe().loc[stats]\n",
    "\n",
    "    return np.allclose(act, des, rtol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 1a: Identifying Issues with the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Use the `head` command on your three files again. This time, describe at least one potential problem with the data you see. Consider issues with missing values and bad data.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "manual: True\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "We will explore each file in turn, including determining its granularity and primary keys and exploring many of the variables individually. Let's begin with the businesses file, which has been read into the `bus` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "## Question 1b: Examining the Business Data File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From its name alone, we expect the `bus.csv` file to contain information about the restaurants. Let's investigate the granularity of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `bus` dataframe contains a column called `business id column` which probably corresponds to a unique business id.  However, we will first rename that column to `bid` for simplicity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus = bus.rename(columns={\"business id column\": \"bid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Examining the entries in `bus`, is the `bid` unique for each record (i.e. each row of data)? Your code should compute the answer, i.e. don't just hard code `True` or `False`.\n",
    "\n",
    "Hint: use `value_counts()` or `unique()` to determine if the `bid` series has any duplicates.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_bid_unique = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 1c\n",
    "\n",
    "We will now work with some important fields in `bus`. In the two cells below create the following **two numpy arrays**:\n",
    "\n",
    "1. Assign `top_names` to the top 5 most frequently used business names, from most frequent to least frequent.\n",
    "2. Assign `top_addresses` to the top 5 addressses where businesses are located, from most popular to least popular.\n",
    "\n",
    "Hint: you may find `value_counts()` helpful. \n",
    "\n",
    "**Step 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_names = ...\n",
    "top_addresses = ...\n",
    "top_names, top_addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 1d\n",
    "\n",
    "Based on the above exploration, answer each of the following questions about `bus` by assigning your answers to the corresponding variables\n",
    "\n",
    "1. What does each record represent?  \n",
    "1. What is the minimal primary key? \n",
    "\n",
    "Minial primary key: a minimal set of attributes (columns) that uniquely specify a row in a table\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does each record represent?  Valid answers are:\n",
    "#    \"One location of a restaurant.\"\n",
    "#    \"A chain of restaurants.\"\n",
    "#    \"A city block.\"\n",
    "q1d_part1 = ...\n",
    "\n",
    "# What is the minimal primary key? Valid answers are:\n",
    "#    \"bid\"\n",
    "#    \"bid, name\"\n",
    "#    \"bid, name, address\"\n",
    "q1d_part2 = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "\n",
    "# 2: Cleaning the Business Data Postal Codes\n",
    "\n",
    "The business data contains postal code information that we can use to aggregate the ratings over regions of the city.  Let's examine and clean the postal code field.  The postal code (sometimes also called a ZIP code) partitions the city into regions:\n",
    "\n",
    "<img src=\"https://www.usmapguide.com/wp-content/uploads/2019/03/printable-san-francisco-zip-code-map.jpg\" alt=\"ZIP Code Map\" style=\"width: 600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a4c4a09f1ecf2f4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Question 2a\n",
    "\n",
    "How many restaurants are in each ZIP code? \n",
    "\n",
    "In the cell below, create a **series** where the index is the postal code and the value is the number of records with that postal code in descending order of count. You may need to use `groupby()`, `size()`, or `value_counts()`. Do you notice any odd/invalid zip codes?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2151d673e6c36a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "zip_counts = ...\n",
    "print(zip_counts.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Question 2b\n",
    "\n",
    "Answer the question about the `postal_code` column in the `bus` dataframe.\n",
    "\n",
    "1. What Python data type is used to represent a ZIP code?\n",
    "\n",
    "*Note*: ZIP codes and postal codes are the same thing.\n",
    "\n",
    "Please write your answers in the variables below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# What Python data type is used to represent a ZIP code? \n",
    "#    \"str\"\n",
    "#    \"int\"\n",
    "#    \"bool\"\n",
    "#    \"float\"\n",
    "q2b = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2c\n",
    "\n",
    "In question 2a we noticed a large number of potentially invalid ZIP codes (e.g., \"Ca\").  These are likely due to data entry errors.  To get a better understanding of the potential errors in the zip codes we will:\n",
    "\n",
    "1. Import a list of valid San Francisco ZIP codes by using `pd.read_json` to load the file `data/sf_zipcodes.json` and extract a **series** of type `str` containing the valid ZIP codes.  *Hint: set `dtype` when invoking `read_json`.*\n",
    "1. Construct a `DataFrame` containing only the businesses which DO NOT have valid ZIP codes.  You will probably want to use the `Series.isin` function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2ci\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_zips = ...\n",
    "valid_zips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Step 2**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2cii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_zip_bus = ...\n",
    "invalid_zip_bus.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2d\n",
    "\n",
    "In the previous question, many of the businesses had a common invalid postal code that was likely used to encode a MISSING postal code.  Do they all share a potentially \"interesting address\"?\n",
    "\n",
    "In the following cell, construct a **series** that counts the number of businesses at each `address` that have this single likely MISSING postal code value.  Order the series in descending order by count. \n",
    "\n",
    "After examining the output, please answer the following question (2e) by filling in the appropriate variable. If we were to drop businesses with MISSING postal code values would a particular class of business be affected?  If you are unsure try to search the web for the most common addresses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_zip_address_count = ...\n",
    "missing_zip_address_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 2e\n",
    "\n",
    "Examine the `invalid_zip_bus` dataframe we computed above and look at the businesses that DO NOT have the special MISSING ZIP code value.  Some of the invalid postal codes are just the full 9 digit code rather than the first 5 digits.  Create a new column named `postal5` in the original `bus` dataframe which contains only the first 5 digits of the `postal_code` column.   Finally, for any of the `postal5` ZIP code entries that were not a valid San Fransisco ZIP Code (according to `valid_zips`) set the entry to `None`.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus['postal5'] = None\n",
    "...\n",
    "\n",
    "# Checking the corrected postal5 column\n",
    "bus.loc[invalid_zip_bus.index, ['bid', 'name', 'postal_code', 'postal5']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# 3: Investigate the Inspection Data\n",
    "\n",
    "Let's now turn to the inspection DataFrame. Earlier, we found that `ins` has 4 columns named \n",
    "`iid`, `score`, `date` and `type`.  In this section, we determine the granularity of `ins` and investigate the kinds of information provided for the inspections. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-174ed23c543ad9da",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Let's start by looking again at the first 5 rows of `ins` to see what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f0fbe724a2783e33",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "ins.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3a\n",
    "\n",
    "The column `iid` probably corresponds to an inspection id.  Is it a primary key?  Write an expression (line of code) that evaluates to `True` or `False` based on whether all the values are unique.\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ins_iid_a_primary_key = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3b\n",
    "\n",
    "The column `iid` appears to be the composition of two numbers and the first number looks like a business id.  \n",
    "\n",
    "**Part 1.**: Create a new column called `bid` in the `ins` dataframe containing just the business id.  You will want to use `ins['iid'].str` operations to do this.  Also be sure to convert the type of this column to `int`\n",
    "\n",
    "**Part 2.**: Then compute how many values in this new column are invalid business ids (i.e. do not appear in the `bus['bid']` column). Consider using the `pd.Series.isin` function.\n",
    "\n",
    "\n",
    "**No python `for` loops or list comprehensions required!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3bi\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3bii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_bid_count = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3c\n",
    "\n",
    "What if we are interested in a time component of the inspection data?  We need to examine the date column of each inspection. \n",
    "\n",
    "**Part 1:** What is the type of the individual `ins['date']` entries? You may want to grab the very first entry and use the `type` function in python. \n",
    "\n",
    "**Part 2:** Use `pd.to_datetime` to create a new `ins['timestamp']` column containing of `pd.Timestamp` objects.  These will allow us to do more date manipulation.\n",
    "\n",
    "**Part 3:** What are the earliest and latest dates in our inspection data?  *Hint: you can use `min` and `max` on dates of the correct type.*\n",
    "\n",
    "**Part 4:** We probably want to examine the inspections by year. Create an additional `ins['year']` column containing just the year of the inspection.  Consider using `pd.Series.dt.year` to do this.\n",
    "\n",
    "**No python `for` loops or list comprehensions required!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 1**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3ci\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_date_type = ...\n",
    "ins_date_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3cii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 3**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3ciii\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = ...\n",
    "latest_date = ...\n",
    "\n",
    "print(\"Earliest Date:\", earliest_date)\n",
    "print(\"Latest Date:\", latest_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 4**\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3civ\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3d\n",
    "\n",
    "What is the relationship between the type of inspection over the 2016 to 2019 timeframe? \n",
    "\n",
    "**Part 1**\n",
    "\n",
    "Construct the following table by\n",
    "1. Using the `pivot_table` containing the number (`size`) of inspections for the given `type` and `year`.\n",
    "1. Adding an extra `Total` column to the result using `sum`\n",
    "1. Sort the results in descending order by the `Total`.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>year</th>      <th>2016</th>      <th>2017</th>      <th>2018</th>      <th>2019</th>      <th>Total</th>    </tr>    <tr>      <th>type</th>      <th></th>      <th></th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Routine - Unscheduled</th>      <td>966</td>      <td>4057</td>      <td>4373</td>      <td>4681</td>      <td>14077</td>    </tr>    <tr>      <th>Reinspection/Followup</th>      <td>445</td>      <td>1767</td>      <td>1935</td>      <td>2292</td>      <td>6439</td>    </tr>    <tr>      <th>New Ownership</th>      <td>99</td>      <td>506</td>      <td>528</td>      <td>459</td>      <td>1592</td>    </tr>    <tr>      <th>Complaint</th>      <td>91</td>      <td>418</td>      <td>512</td>      <td>437</td>      <td>1458</td>    </tr>    <tr>      <th>New Construction</th>      <td>102</td>      <td>485</td>      <td>218</td>      <td>189</td>      <td>994</td>    </tr>    <tr>      <th>Non-inspection site visit</th>      <td>51</td>      <td>276</td>      <td>253</td>      <td>231</td>      <td>811</td>    </tr>    <tr>      <th>New Ownership - Followup</th>      <td>0</td>      <td>45</td>      <td>219</td>      <td>235</td>      <td>499</td>    </tr>    <tr>      <th>Structural Inspection</th>      <td>1</td>      <td>153</td>      <td>50</td>      <td>190</td>      <td>394</td>    </tr>    <tr>      <th>Complaint Reinspection/Followup</th>      <td>19</td>      <td>68</td>      <td>70</td>      <td>70</td>      <td>227</td>    </tr>    <tr>      <th>Foodborne Illness Investigation</th>      <td>1</td>      <td>29</td>      <td>50</td>      <td>35</td>      <td>115</td>    </tr>    <tr>      <th>Routine - Scheduled</th>      <td>0</td>      <td>9</td>      <td>8</td>      <td>29</td>      <td>46</td>    </tr>    <tr>      <th>Administrative or Document Review</th>      <td>2</td>      <td>1</td>      <td>1</td>      <td>0</td>      <td>4</td>    </tr>    <tr>      <th>Multi-agency Investigation</th>      <td>0</td>      <td>0</td>      <td>1</td>      <td>2</td>      <td>3</td>    </tr>    <tr>      <th>Special Event</th>      <td>0</td>      <td>3</td>      <td>0</td>      <td>0</td>      <td>3</td>    </tr>    <tr>      <th>Community Health Assessment</th>      <td>1</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>1</td>    </tr>  </tbody></table>\n",
    "\n",
    "**No python `for` loops or list comprehensions required!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_pivot = ...\n",
    "ins_pivot = ...\n",
    "...\n",
    "ins_pivot_sorted = ...\n",
    "ins_pivot_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Part 2**\n",
    "\n",
    "Based on the above analysis, which year appears to have had a lot of businesses in newly constructed buildings?\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3dii\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_of_new_construction = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "## Question 3e\n",
    "\n",
    "Let's examine the inspection scores `ins['score']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins['score'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a large number of inspections with the `'score'` of `-1`.   These are probably missing values.  Let's see what type of inspections have scores and which do not. Create the following dataframe using steps similar to the previous question, and assign it to to the variable `ins_missing_score_pivot`.\n",
    "\n",
    "You should observe that inspection scores appear only to be assigned to `Routine - Unscheduled` inspections.\n",
    "\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th>Missing Score</th>      <th>False</th>      <th>True</th>      <th>Total</th>    </tr>    <tr>      <th>type</th>      <th></th>      <th></th>      <th></th>    </tr>  </thead>  <tbody>    <tr>      <th>Routine - Unscheduled</th>      <td>14031</td>      <td>46</td>      <td>14077</td>    </tr>    <tr>      <th>Reinspection/Followup</th>      <td>0</td>      <td>6439</td>      <td>6439</td>    </tr>    <tr>      <th>New Ownership</th>      <td>0</td>      <td>1592</td>      <td>1592</td>    </tr>    <tr>      <th>Complaint</th>      <td>0</td>      <td>1458</td>      <td>1458</td>    </tr>    <tr>      <th>New Construction</th>      <td>0</td>      <td>994</td>      <td>994</td>    </tr>    <tr>      <th>Non-inspection site visit</th>      <td>0</td>      <td>811</td>      <td>811</td>    </tr>    <tr>      <th>New Ownership - Followup</th>      <td>0</td>      <td>499</td>      <td>499</td>    </tr>    <tr>      <th>Structural Inspection</th>      <td>0</td>      <td>394</td>      <td>394</td>    </tr>    <tr>      <th>Complaint Reinspection/Followup</th>      <td>0</td>      <td>227</td>      <td>227</td>    </tr>    <tr>      <th>Foodborne Illness Investigation</th>      <td>0</td>      <td>115</td>      <td>115</td>    </tr>    <tr>      <th>Routine - Scheduled</th>      <td>0</td>      <td>46</td>      <td>46</td>    </tr>    <tr>      <th>Administrative or Document Review</th>      <td>0</td>      <td>4</td>      <td>4</td>    </tr>    <tr>      <th>Multi-agency Investigation</th>      <td>0</td>      <td>3</td>      <td>3</td>    </tr>    <tr>      <th>Special Event</th>      <td>0</td>      <td>3</td>      <td>3</td>    </tr>    <tr>      <th>Community Health Assessment</th>      <td>0</td>      <td>1</td>      <td>1</td>    </tr>  </tbody></table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_missing_score_pivot = ...\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that inspection scores appear only to be assigned to `Routine - Unscheduled` inspections. It is reasonable that for inspection types such as `New Ownership` and `Complaint` to have no associated inspection scores, but we might be curious why there are no inspection scores for the `Reinspection/Followup` inspection type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "business-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "---\n",
    "\n",
    "<br/><br/><br/>\n",
    "\n",
    "# 4: Joining Data Across Tables\n",
    "\n",
    "In this question we will start to connect data across mulitple tables.  We will be using the `merge` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 4a\n",
    "\n",
    "Let's figure out which restaurants had the lowest scores. Before we proceed, let's filter out missing scores from `ins` so that negative scores don't influence our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins = ins[ins[\"score\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "We'll start by creating a new dataframe called `ins_named`. It should be exactly the same as `ins`, except that it should have the name and address of every business, as determined by the `bus` dataframe. If a `business_id` in `ins` does not exist in `bus`, the name and address should be given as `NaN`. \n",
    "\n",
    "*Hint*: Use the merge method to join the `ins` dataframe with the appropriate portion of the `bus` dataframe. See the official [documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) on how to use `merge`.\n",
    "\n",
    "*Note*: For quick reference, a pandas 'left' join keeps the keys from the left frame, so if `ins` is the left frame, all the keys from `ins` are kept and if a set of these keys don't have matches in the other frame, the columns from the other frame for these \"unmatched\" key rows contains NaNs.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4a\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ins_named = ...\n",
    "...\n",
    "ins_named.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 4b\n",
    "\n",
    "Let's look at the 20 businesses with the lowest **median** score.  Order your results by the median score followed by the business id to break ties. The resulting table should look like:\n",
    "\n",
    "\n",
    "*Hint: You may find the `as_index` argument in the `groupby` method important*. [The documentation is linked here!](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">  <thead>    <tr style=\"text-align: right;\">      <th></th>      <th>bid</th>      <th>name</th>      <th>median score</th>    </tr>  </thead>  <tbody>    <tr>      <th>3876</th>      <td>84590</td>      <td>Chaat Corner</td>      <td>54.0</td>    </tr>    <tr>      <th>4564</th>      <td>90622</td>      <td>Taqueria Lolita</td>      <td>57.0</td>    </tr>    <tr>      <th>4990</th>      <td>94351</td>      <td>VBowls LLC</td>      <td>58.0</td>    </tr>    <tr>      <th>2719</th>      <td>69282</td>      <td>New Jumbo Seafood Restaurant</td>      <td>60.5</td>    </tr>    <tr>      <th>222</th>      <td>1154</td>      <td>SUNFLOWER RESTAURANT</td>      <td>63.5</td>    </tr>    <tr>      <th>1991</th>      <td>39776</td>      <td>Duc Loi Supermarket</td>      <td>64.0</td>    </tr>    <tr>      <th>2734</th>      <td>69397</td>      <td>Minna SF Group LLC</td>      <td>64.0</td>    </tr>    <tr>      <th>3291</th>      <td>78328</td>      <td>Golden Wok</td>      <td>64.0</td>    </tr>    <tr>      <th>4870</th>      <td>93150</td>      <td>Chez Beesen</td>      <td>64.0</td>    </tr>    <tr>      <th>4911</th>      <td>93502</td>      <td>Smoky Man</td>      <td>64.0</td>    </tr>    <tr>      <th>5510</th>      <td>98995</td>      <td>Vallarta's Taco Bar</td>      <td>64.0</td>    </tr>    <tr>      <th>1457</th>      <td>10877</td>      <td>CHINA FIRST INC.</td>      <td>64.5</td>    </tr>    <tr>      <th>2890</th>      <td>71310</td>      <td>Golden King Vietnamese Restaurant</td>      <td>64.5</td>    </tr>    <tr>      <th>4352</th>      <td>89070</td>      <td>Lafayette Coffee Shop</td>      <td>64.5</td>    </tr>    <tr>      <th>505</th>      <td>2542</td>      <td>PETER D'S RESTAURANT</td>      <td>65.0</td>    </tr>    <tr>      <th>2874</th>      <td>71008</td>      <td>House of Pancakes</td>      <td>65.0</td>    </tr>    <tr>      <th>818</th>      <td>3862</td>      <td>IMPERIAL GARDEN SEAFOOD RESTAURANT</td>      <td>66.0</td>    </tr>    <tr>      <th>2141</th>      <td>61427</td>      <td>Nick's Foods</td>      <td>66.0</td>    </tr>    <tr>      <th>2954</th>      <td>72176</td>      <td>Wolfes Lunch</td>      <td>66.0</td>    </tr>    <tr>      <th>4367</th>      <td>89141</td>      <td>Cha Cha Cha on Mission</td>      <td>66.5</td>    </tr>  </tbody></table>\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4b\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twenty_lowest_scoring = ... \n",
    "...\n",
    "\n",
    "twenty_lowest_scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<br/><br/><br/>\n",
    "\n",
    "--- \n",
    "\n",
    "## Question 4c\n",
    "\n",
    "Let's now examine the descriptions of violations for inspections with `score > 0` and `score < 65`.  Construct a **Series** indexed by the `description` of the violation from the `vio` table with the value being the number of times that violation occured for inspections with the above score range.  Sort the results in descending order of the count.\n",
    "\n",
    "The first few entries should look like:\n",
    "\n",
    "```\n",
    "Unclean or unsanitary food contact surfaces                                  43\n",
    "High risk food holding temperature                                           42\n",
    "Unclean or degraded floors walls or ceilings                                 40\n",
    "Unapproved or unmaintained equipment or utensils                             39\n",
    "```\n",
    "You will need to use `merge` twice.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_score_violations = ...\n",
    "\n",
    "...\n",
    "\n",
    "low_score_violations.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 4d\n",
    "\n",
    "Let's figure out which restaurant had the worst scores ever (single lowest score). \n",
    "\n",
    "**In the cell below, write the name of the restaurant** with the lowest inspection scores ever. You can also head to yelp.com and look up the reviews page for this restaurant. Feel free to add anything interesting you want to share.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_restaurant = ...\n",
    "worst_restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You have finished Homework 2! ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
